{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import tiktoken\n",
    "import sys\n",
    "import utils\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the OpenAI API Key\n",
    "openai.api_key  = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function auto completes GPT's reponse\n",
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, \n",
    "                                 max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to repond to the user and moderate question and response\n",
    "def process_user_message(user_input, all_messages, debug=True):\n",
    "    delimiter = \"####\"\n",
    "    user_input = user_input.replace(delimiter, \"\")\n",
    "    \n",
    "    # Step 1: Check input to see if it flags the Moderation API or is a prompt injection\n",
    "    response = openai.Moderation.create(input=user_input)\n",
    "    moderation_output = response[\"results\"][0]\n",
    "\n",
    "    if moderation_output[\"flagged\"]:\n",
    "        print(\"Step 1: Input flagged by Moderation API.\")\n",
    "        return \"Sorry, we cannot process this request.\"\n",
    "\n",
    "    if debug: print(\"Step 1: Input passed moderation check.\")\n",
    "\n",
    "    # Step 2: Answer the user question\n",
    "    system_message = f\"\"\"\n",
    "    Follow these steps to answer the patient queries.\n",
    "    The patient query will be delimited with four hashtags,\\\n",
    "    i.e. {delimiter}. \n",
    "\n",
    "    Step 1:#### First categorize the user's query into one \\\n",
    "    of the following categories: (1) The user is asking for general information about a \\\n",
    "    condition. (2) The user is listing symptoms and wants information \\\n",
    "    on what is wrong with them. (3) The user wants information on a type of doctor and what they do. \\\n",
    "    (4) The user wants to know more about a mental health related issue \\\n",
    "    and what they can do. (5) The user is not asking about anything medical related do not categorize \\\n",
    "    the query.\n",
    "\n",
    "    Step 2:#### Based on how the user's query was categorized above do \\\n",
    "    the following based on the category number: (1) List common symptoms of the condition, state how to resolve the \\\n",
    "    issue and how to prevent it. (2) If very little information was given about their symptoms, \\\n",
    "    then ask more follow up questions to narrow down that is wrong. Make sure to ask the user relevant follow-up questions. \\\n",
    "    Give them specific prompts and ask specific questions. (5) If the user is greeting you, \\\n",
    "    answer their question and respond back. Otherwise tell the user that you cannot help them with this query and \\\n",
    "    let them know that you can help with anything medical related\n",
    "\n",
    "    Step 3:#### If the query was placed in catergory (2) and you are sure of the patient's condition, \\\n",
    "    then decide wether the user is in critical condition or not. If they are in critical \\\n",
    "    condition tell the user how they can minimize risks immediately \\\n",
    "    and to contact a local doctor. If they are able to treat \\\n",
    "    the issue themselves and are not in critical condition, \\\n",
    "    then tell them how to treat the issue. Answer \\\n",
    "    to the patient in a friendly and helpful tone. \n",
    "    \n",
    "    Remember to always have a reponse to user!\n",
    "\n",
    "    Use the following format:\n",
    "    Step 1:#### <step 1 reasoning>\n",
    "    Step 2:#### <step 2 reasoning>\n",
    "    Step 3:#### <step 3 reasoning>\n",
    "    Response to user:#### <response to customer>\n",
    "\n",
    "    Make sure to include {delimiter} to separate every step.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': f\"{delimiter}{user_input}{delimiter}\"}\n",
    "    ]\n",
    "\n",
    "    final_response = get_completion_from_messages(all_messages + messages)\n",
    "    if debug:print(\"Step 2: Generated response to user question.\")\n",
    "    all_messages = all_messages + messages[1:]\n",
    "\n",
    "    # Step 3: Put the answer through the Moderation API\n",
    "    response = openai.Moderation.create(input=final_response)\n",
    "    moderation_output = response[\"results\"][0]\n",
    "\n",
    "    if moderation_output[\"flagged\"]:\n",
    "        if debug: print(\"Step 3: Response flagged by Moderation API.\")\n",
    "        return \"Sorry, we cannot provide this information.\"\n",
    "\n",
    "    if debug: print(\"Step 3: Response passed moderation check.\")\n",
    "\n",
    "    return final_response, all_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect all messages\n",
    "def collect_messages(user_input, context, debug=False):\n",
    "    print(f\"\\nUser Input = {user_input}\")\n",
    "    if user_input == \"\":\n",
    "        return \"\", context\n",
    "    #response, context = process_user_message(user_input, context, utils.get_products_and_category(),debug=True)\n",
    "    response, context = process_user_message(user_input, context, debug=False)\n",
    "    \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    return response, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Input = are you a bundy face?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"Step 1: This query does not fall into any of the medical-related categories.\\n\\nStep 2: Since the user is not asking anything medical-related, I will inform them that I cannot help with their query and let them know that I am here to assist with any medical-related questions or concerns.\\n\\nStep 3: N/A\\n\\nResponse to user: I'm sorry, but I am here to assist with any medical-related questions or concerns you may have. If you have any health-related inquiries, feel free to ask, and I'll be happy to help!\",\n",
       " [{'role': 'user', 'content': '####are you a bundy face?####'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"Step 1: This query does not fall into any of the medical-related categories.\\n\\nStep 2: Since the user is not asking anything medical-related, I will inform them that I cannot help with their query and let them know that I am here to assist with any medical-related questions or concerns.\\n\\nStep 3: N/A\\n\\nResponse to user: I'm sorry, but I am here to assist with any medical-related questions or concerns you may have. If you have any health-related inquiries, feel free to ask, and I'll be happy to help!\"}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_messages('are you a bundy face?', [])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('Basic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e17ab0072952413781c2175f0b7035984dd5be5c130a6a9f3fa530e3797acf38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
